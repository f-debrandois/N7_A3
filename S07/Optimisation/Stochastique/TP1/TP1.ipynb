{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression linéaire et gradient stochastique\n",
    "\n",
    "Ce TD-TP a pour objectif de plonger de manière un peu plus individualisée dans le cours d’optimisation stochastique. Il n’est pas noté, mais j’encourage très vivement les étudiants à rédiger consciencieusement leurs réponses et leurs idées. La rédaction force à mieux présenter les choses et surtout à mieux les cerner. Ca me permettra aussi plus facilement de corriger d’éventuelles incompréhensions.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "L’objectif de ce TP est d’illustrer la première partie du cours d’optimisation stochastique sur les erreurs en apprentissage et d’implémenter les premières versions du gradient stochastique. Il a aussi pour objectif de vous entraîner à effectuer des calculs avec des variables aléatoires pour les rendre plus accessibles et mieux comprendre les cours à venir.\n",
    "\n",
    "Nous allons nous placer dans le cadre de travail le plus simple : la régression linéaire. Ce cadre présente plusieurs avantages :\n",
    "- C’est probablement le plus simple d’un point de vue théorique et il permet d’appréhender de nombreux phénomènes avec des mathématiques relativement élémentaires.\n",
    "\n",
    "- C’est probablement encore le plus utilisé dans les applications, et il me semble nécessaire de le comprendre profondément."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Le cadre\n",
    "Soit $X$ un vecteur aléatoire de $\\mathbb{R}^d$, pour $d \\in \\mathbb{N}$ suivant une certaine distribution de probabilité inconnue $P_X$. Pour un certain vecteur $\\theta \\in \\mathbb{R}^d$, on construit une variable aléatoire $Y \\in \\mathbb{R}$ définie par :\n",
    "$$\n",
    "Y = \\langle \\theta, X\\rangle + B \\quad \\text{ où } \\quad B \\sim \\mathcal{N}(0, \\sigma^2) \\text{ est une variable aléatoire gaussienne indépendante de } X.\n",
    "$$\n",
    "\n",
    "> L’objectif de ce TP est d’apprendre le vecteur $\\theta$ inconnu à partir de $n \\in \\mathbb{N}$ observations $(x_i, y_i)_{1 \\leq i \\leq n}$ tirées indépendamment suivant la loi $P$.\n",
    "\n",
    "Pour ce faire, on peut simplement résoudre le problème de minimisation du risque empirique suivant :\n",
    "\n",
    "\\begin{equation}\n",
    "    \\underset{\\omega \\in \\mathbb{R}^d}{inf} E_n(\\omega) = \\frac{1}{2n} \\sum_{i = 1}^{n} (\\langle \\omega, x_i \\rangle - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "On notera $\\omega_n^*$ n’importe quel minimiseur (sous réserve d’existence) du problème ci-dessus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Travail pratique (théorie)\n",
    "Dans ce travail nous supposerons simplement que $X \\sim \\mathcal{N}(0, I_d)$. Nous supposons aussi que $\\theta_i = 1$ pour tout $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = 10\n",
    "n = 1000\n",
    "theta = np.ones((d, 1))\n",
    "sigma = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Définir une fonction \\\n",
    "$\\texttt{X, Y = generate\\_data(d,n,theta,sigma)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(d, n, theta, sigma):\n",
    "    # Vecteur X -> N(0, I_d)\n",
    "    X = np.random.normal(0, 1, size=(n, d))\n",
    "\n",
    "    # Variable gaussienne B\n",
    "    B = np.random.normal(0, sigma, size=(n, 1))\n",
    "\n",
    "    # Construction de Y : Y = <theta, X> + B\n",
    "    Y = np.dot(X, theta) + B\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = generate_data(d, n, theta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Définir une fonction qui renvoit le risque moyen \\\n",
    "$\\texttt{E(w,theta,sigma)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(w, theta, sigma):\n",
    "    return (1/2) * np.linalg.norm(w - theta)**2 + (sigma**2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Définir une fonction qui renvoit le risque empirique \\\n",
    "$\\texttt{En(w,X,Y)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def En(w, X, Y):\n",
    "    n = len(Y)\n",
    "\n",
    "    # Difference entre Xw et Y\n",
    "    squared_diff = np.square(np.dot(X, w) - Y)\n",
    "\n",
    "    # Risque empirique\n",
    "    empirical_risk = 0.5 * np.sum(squared_diff) / n\n",
    "\n",
    "    return empirical_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Définir une fonction qui renvoit le gradient du risque empirique \\\n",
    "$\\texttt{grad\\_En(w,X,Y)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_En(w, X, Y):\n",
    "    n = len(Y)\n",
    "\n",
    "    # Différence entre Xw et Y\n",
    "    diff = np.dot(X, w) - Y\n",
    "\n",
    "    # Gradient du risque empirique\n",
    "    gradient = (1/n) * np.dot(X.T, diff)\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Définir une fonction qui renvoit le gradient stochastique suivant la loi uniforme \\\n",
    "$\\texttt{grad\\_sto\\_En(w,X,Y,n\\_batch)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_sto_En(w, X, Y, n_batch):\n",
    "    n = len(Y)\n",
    "\n",
    "    # Choisir des indices aléatoires pour le batch\n",
    "    batch_indices = np.random.choice(n, size=n_batch, replace=False)\n",
    "\n",
    "    # Selectionner les données du batch\n",
    "    X_batch = X[batch_indices, :]\n",
    "    Y_batch = Y[batch_indices]\n",
    "\n",
    "    # Calculer la différence entre Xw et Y\n",
    "    diff_batch = np.dot(X_batch, w) - Y_batch\n",
    "\n",
    "    # Calculer le gradient stochastique du risque empirique\n",
    "    stochastic_gradient = (1/n_batch) * np.dot(X_batch.T, diff_batch)\n",
    "\n",
    "    return stochastic_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculer la constante de Lipschitz de $\\nabla E_n$ numériquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipschitz constant :  3.2184269609159117\n"
     ]
    }
   ],
   "source": [
    "def lipschitz_constant(X):\n",
    "    n = len(X)\n",
    "\n",
    "    # Constante de Lipschitz\n",
    "    L = (1/n) * np.linalg.norm(np.dot(X.T, X))\n",
    "\n",
    "    return L\n",
    "\n",
    "print(\"Lipschitz constant : \", lipschitz_constant(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Si vous aviez un choix, quelle méthode d’optimisation vous semblerait la plus efficace pour minimiser $E_n$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Effectuer une descente de gradient à pas constant sur $E_n$ et stocker les suites $E_n(\\omega_k)$ et $E(\\omega_k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, w_init, alpha, n_iterations):\n",
    "    w = w_init\n",
    "    En_history = []\n",
    "    E_history = []\n",
    "\n",
    "    for k in range(n_iterations):\n",
    "        # Calculer le gradient du risque empirique\n",
    "        gradient = grad_En(w, X, Y)\n",
    "\n",
    "        # Mettre à jour le vecteur de poids\n",
    "        w = w - alpha * gradient\n",
    "\n",
    "        # Calculer et stocker le risque empirique\n",
    "        En_k = En(w, X, Y)\n",
    "        En_history.append(En_k)\n",
    "\n",
    "        # Calculer et stocker l'erreur de prédiction\n",
    "        E_k = E(w, theta, sigma)\n",
    "        E_history.append(E_k)\n",
    "\n",
    "    return En_history, E_history\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "n_iterations = 100\n",
    "w_init = np.random.rand(d, 1)\n",
    "\n",
    "En_history, E_history = gradient_descent(X, Y, w_init, alpha, n_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Etudier l’erreur d’approximation $||\\omega_n^* - \\theta ||_2^2$ en fonction de $n$. Expliquez vos observations à partir du cours et des questions théoriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Effectuer un algorithme de gradient stochastique à pas constant sur $E_n$ et stocker les suites $E_n(\\omega_k)$ et $E(\\omega_k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, w_init, alpha, n_iterations):\n",
    "    w = w_init\n",
    "    n = len(Y)\n",
    "    En_history = []\n",
    "    E_history = []\n",
    "\n",
    "    for k in range(n_iterations):\n",
    "        # Choisir le nombre de données dans le batch\n",
    "        n_batch = np.random.randint(1, n)\n",
    "\n",
    "        # Calculer le gradient stochastique du risque empirique\n",
    "        gradient = grad_sto_En(w, X, Y, n_batch)\n",
    "\n",
    "        # Mettre à jour le vecteur de poids\n",
    "        w = w - alpha * gradient\n",
    "\n",
    "        # Calculer et stocker le risque empirique\n",
    "        En_k = En(w, X, Y)\n",
    "        En_history.append(En_k)\n",
    "\n",
    "        # Calculer et stocker l'erreur de prédiction\n",
    "        E_k = E(w, theta, sigma)\n",
    "        E_history.append(E_k)\n",
    "\n",
    "    return En_history, E_history\n",
    "\n",
    "alpha = 0.01\n",
    "n_iterations = 100\n",
    "w_init = np.random.rand(d, 1)\n",
    "\n",
    "En_history_stoc, E_history_stoc = stochastic_gradient_descent(X, Y, w_init, alpha, n_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Effectuer un algorithme de gradient stochastique à pas décroissant sur $E_n$ et stocker les suites $E_n(\\omega_k)$ et $E(\\omega_k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_step(X, Y, w_init, n_iterations):\n",
    "    w = w_init\n",
    "    n = len(Y)\n",
    "    En_history = []\n",
    "    E_history = []\n",
    "\n",
    "    for k in range(1, n_iterations + 1):\n",
    "        # Choisir le nombre de données dans le batch\n",
    "        n_batch = np.random.randint(1, n)\n",
    "\n",
    "        # Calculer le gradient stochastique du risque empirique\n",
    "        gradient = grad_sto_En(w, X, Y, n_batch)\n",
    "\n",
    "        # Mettre à jour le vecteur de poids avec un pas de descente adaptatif\n",
    "        alpha_k = 1 / np.sqrt(k)\n",
    "        w = w - alpha_k * gradient\n",
    "\n",
    "        # Calculer et stocker le risque empirique\n",
    "        En_k = En(w, X, Y)\n",
    "        En_history.append(En_k)\n",
    "\n",
    "        # Calculer et stocker l'erreur de prédiction\n",
    "        E_k = E(w, theta, sigma)\n",
    "        E_history.append(E_k)\n",
    "\n",
    "    return En_history, E_history\n",
    "\n",
    "\n",
    "n_iterations = 100\n",
    "w_init = np.random.rand(d, 1)\n",
    "\n",
    "En_history_step, E_history_step = stochastic_gradient_descent_step(X, Y, w_init, n_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Comparer les taux de convergence pour le risque empirique et le risque moyen en fonction du nombre d’epoch pour chaque méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Implémenter un algorithme de gradient stochastique online et comparer aux précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Implémenter la méthode SAGA et comparer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Relier les observations au cours. Quelle méthode devrait être privilégiée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Etudier l’influence de $n$, de $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Travail pratique (pratique)\n",
    "Pour finir ce TP, nous proposons de tester les algorithmes de gradient stochastique dans un cadre moderne, avec la librairie PyTorch et des réseaux de Neurones. De très nombreux tutoriels sur ces logiciels existent et sont bien réalisés.\n",
    "\n",
    "> Je vous propose ici de suivre le tutoriel suivant : [pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist).\n",
    "\n",
    "Une fois que vous avez réussi à reproduire les expériences suggérées, comparez différents algorithmes d’optimisation disponibles sous PyTorch (SGD simple, SGD Momentum, RMSProp, SAGA, ADAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. L’inégalité de Bernstein (inégalité de concentration)\n",
    "$\\textbf{Théorème 1 }$ (Inégalité de Bernstein). $\\textit{Soient } Z_1, \\dots , Z_n \\textit{ un ensemble de } n \\textit{ vecteurs aléatoires indépendants et identiquement distribués tels que } |Z_i| \\leq c \\textit{ presque sûrement, } \\mathbb{E}(Z_i) = \\mu \\textit{ et } Var(Z_i) = \\sigma^2 \\textit{. Alors : }$\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbb{P}(|\\frac{1}{n}\\sum_{i = 1}^n Z_i - \\mu | \\geq t) \\leq 2 \\exp(\\frac{nt^2}{2 \\sigma^2 + 2 ct /3}).\n",
    "\\end{equation}\n",
    "\n",
    "Ce type d’inégalité est appelé inégalité de concentration. Il indique que la probabilité que la moyenne empirique dévie de la moyenne est très faible si on a un nombre d’observations suffisant.\n",
    "\n",
    "1. Etablir la proposition suivante : l’inégalité suivante est valide avec une probabilité supérieure à $1 − \\delta$.\n",
    "\n",
    "2. On aimerait montrer que $E_n$ est proche de $E$. Comment utiliser l’inégalité de Bernstein ou le corollaire précédent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
