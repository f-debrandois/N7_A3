{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50eb139-5964-4b5a-af0e-e4b69e1560aa",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "_Sentiment analysis through Recurrent Neural Networks_\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, we are interested in the problem of sentiment analysis. In the first part, we will build a recurrent network on a toy dataset from scratch to determine if a sentence is positive or negative. In a second step, using the [`Keras`](https://keras.io/) API, we will build a network able to determine if a movie review is positive or negative.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef5871b-799b-40e5-a2b0-863bfcf6e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7b446-678c-45fe-80e4-a49c8448f3e2",
   "metadata": {},
   "source": [
    "---\n",
    "# **PART I**: RNN from Scratch\n",
    "\n",
    "In order to understand recurrent networks in more detail, our first example will be implementing a network from scratch. The network will perform a (simple) sentiment analysis task, namely determining whether a given text string is positive or negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a36b5-ac50-4a26-9b14-e7a61017eac8",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "The commands below allow displaying some samples of our toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73ff428-67f1-4538-89e2-e254c86e0051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', True),\n",
       " ('bad', False),\n",
       " ('happy', True),\n",
       " ('sad', False),\n",
       " ('not good', False),\n",
       " ('not bad', True),\n",
       " ('not happy', False),\n",
       " ('not sad', True),\n",
       " ('very good', True),\n",
       " ('very bad', False),\n",
       " ('very happy', True),\n",
       " ('very sad', False),\n",
       " ('i am happy', True),\n",
       " ('this is good', True),\n",
       " ('i am bad', False)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import train_data, test_data\n",
    "\n",
    "display( list(train_data.items())[:15] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170f3e9-18b4-421d-a112-fb06cf127bf1",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "In order to visualize quickly the labels, we want display in _green_ the <span style=\"color:green\">positive sentences</span>, and in _red_ the <span style=\"color:orangered\">negative sentences</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f371d9b-de65-4f33-9a2c-2f482ccaa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c949fe-5a45-461c-99f7-8baba3fc7528",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Using the command `Fore.COLOR` of the package [`colorama`](https://pypi.org/project/colorama/), realize such a function.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f973db-c41a-47b7-909e-7e3b7e880778",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def coloredSentences(sentences, out=15):\n",
    "    \"\"\"\n",
    "    Display in green the positive sentences, and in red the negative sentences\n",
    "    - sentences is a dict\n",
    "        - sentences.keys() are the sentences to display\n",
    "        - sentences.values() are booleans that encode the sentiment\n",
    "    - out is an integer indicating the maximum number of sentences to display\n",
    "    \"\"\"\n",
    "    for i, (sentence, sentiment) in enumerate(sentences.items()):\n",
    "        if i == out:\n",
    "            break\n",
    "        if sentiment:\n",
    "            print(Fore.GREEN + sentence)\n",
    "        else:\n",
    "            print(Fore.RED + sentence)\n",
    "    print(Fore.RESET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac11a88-34b0-4c1c-aa8b-9873947646e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/coloredSentences.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983c0401-f9c9-44ab-9ef7-5b4f7bce72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mgood\n",
      "\u001b[31mbad\n",
      "\u001b[32mhappy\n",
      "\u001b[31msad\n",
      "\u001b[31mnot good\n",
      "\u001b[32mnot bad\n",
      "\u001b[31mnot happy\n",
      "\u001b[32mnot sad\n",
      "\u001b[32mvery good\n",
      "\u001b[31mvery bad\n",
      "\u001b[32mvery happy\n",
      "\u001b[31mvery sad\n",
      "\u001b[32mi am happy\n",
      "\u001b[32mthis is good\n",
      "\u001b[31mi am bad\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "coloredSentences(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bcbe8-1af8-4528-8f3c-52851ed1be38",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "\n",
    "The datasets consists of two $\\texttt{dictionaries}$. Before trying to classify these sentences, we will build a vocabulary of all of all words that exist in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f59b2-9f2c-49cc-a18c-7226ab2b39d9",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** How many different words are in our vocabulary?</span>\n",
    "\n",
    "To answer this question, start by building a **vocabulary**, _i.e._ a $\\texttt{list}$ containing all the words used in the dataset. _Each word should occur only once_.\n",
    "\n",
    "<!-- 18 unique words found -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d8981f-29b0-46e7-9ba3-ab5018983886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['right', 'this', 'sad', 'i', 'was', 'at', 'earlier', 'good', 'all', 'bad', 'very', 'am', 'and', 'now', 'happy', 'or', 'not', 'is']\n",
      "--> 18 unique words\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "vocab = list(set(' '.join(train_data.keys()).split(' ')))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary:',vocab)\n",
    "print('--> %d unique words' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93ea5e36-da35-4d9a-a6a7-789c9646cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/vocab_size.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbee304-e47d-4726-bfa6-f09d81b400fd",
   "metadata": {},
   "source": [
    "### Word Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c1bc7-928c-44c9-8169-1b1b591ecd59",
   "metadata": {},
   "source": [
    "A neural network cannot take strings as input. So we have to encode these sentences in a format understandable by a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215ad08-6dd8-4f4e-9fbd-8534963c45f1",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Assign an integer index to represent each word of the vocab</span>\n",
    "\n",
    "To do that, construct two $\\texttt{dictionaries}$ allowing to translate words into integer indices, and vice versa :\n",
    "\n",
    "* $\\texttt{word\\_to\\_idx}$ has for keys the words of the vocabulary; and for value an integer index, the order in which the words appear in the vocabulary for example.\n",
    "* $\\texttt{idx\\_to\\_word}$ performs the opposite translation: its keys are the integer indices while its values are the associated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d068ab-58fe-4c73-87e4-a8ff51610c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of word \"good\": 7\n",
      "First word in the vocabulary: right\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "print('Index of word \"good\":', word_to_idx['good'])\n",
    "print('First word in the vocabulary:', idx_to_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8955a2cb-3d3a-4dd4-b2ef-2a7e5962ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/decode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a93da-4411-446f-bfce-93bf4f47fd51",
   "metadata": {},
   "source": [
    "This way of encoding words works quite well. However, it has the disadvantage of introducing a preferential but meaningless order in how words are processed. Since the vocabulary size is reasonable, we will use a one-shot encoding instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5709bea-e8eb-44e4-ad4a-ec4cdeeb3589",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Write a function $\\texttt{createInputs}$ that performs one-hot encoding</span>\n",
    "\n",
    "This function will return a $\\texttt{list}$ of the one-hot encodings of each word that compose the input sentence. Each word is encoded by a vector consisting of zeros and _a_ one at its \"$\\texttt{word\\_to\\_idx}$\" position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f355dd2-3d90-447e-8452-fad744ddbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def createInputs(text):\n",
    "    '''\n",
    "    Returns an array of one-hot vectors representing the words in the input text string.\n",
    "    - text is a string\n",
    "    - Each one-hot vector has shape (vocab_size, 1)\n",
    "    '''\n",
    "    inputs = []\n",
    "    for w in text.split(' '):\n",
    "        v = np.zeros((vocab_size, 1))\n",
    "        v[word_to_idx[w]] = 1\n",
    "        inputs.append(v)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce782e44-3e95-4e8d-ad66-c1fc8d750c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/createInputs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c99eedd1-887e-485f-a948-db7b6db5d11d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])]\n"
     ]
    }
   ],
   "source": [
    "print( createInputs('i am very good') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa1677-ef5f-4137-9b0e-2ea557497232",
   "metadata": {},
   "source": [
    "## The Forward Phase\n",
    "\n",
    "In this part, we will build the simplest possible recursive network. To do so, we will create an $\\texttt{RNN}$ class that we will update as we build it. We want to classify a textual data. To do so, we will use a many-to-one network, as shown in the figure below.\n",
    "\n",
    "<img src=\"img/many-to-one.png\" width=250>\n",
    "\n",
    "Let a sentence $x=(x_0,\\ldots,x_n)$, its label $y$, and let $h=(h_0,\\ldots,h_n)$ be the corresponding hidden state. We give ourselves three weight matrices, $W_{xh}$, $W_{hh}$ and $W_{hy}$, and two bias vectors, $b_h$ and $b_y$, so that, for any $t\\in[\\![0,n]\\!]$:\n",
    "\n",
    "$$ \\left\\{\\begin{aligned}\n",
    "    h_t &= \\tanh\\left( W_{xh}x_t + W_{hh}h_{t-1} + b_h \\right) \\\\\n",
    "    y &= softmax(W_{hy}h_n + b_y)\n",
    "\\end{aligned}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b536e-0edd-4b0f-9bcf-a3c9a8730cc6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What is the dimension of the different weight matrices and bias vectors?</span>\n",
    "\n",
    "You can freely use the following notations:\n",
    "* $n_h$ denotes the $\\texttt{hidden\\_size}$, _i.e._ the size oh the hidden vectors $h_t$;\n",
    "* $n_x$ denotes the $\\texttt{input\\_size}$, _i.e._ the size of the inputs $x_t$;\n",
    "* $n_y$ denotes the $\\texttt{output\\_size}$, _i.e._ the size of the output $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81fb7e-25ad-409e-abe7-f69441a3b117",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245a61a-05d5-4608-9a7b-d03bb71bec7c",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "**Solution**:\n",
    "* $W_{xh}\\in\\mathcal{M}_{n_h,n_x}(\\mathbb{R})$\n",
    "* $W_{hh}\\in\\mathcal{M}_{n_h,n_h}(\\mathbb{R})$\n",
    "* $W_{hy}\\in\\mathcal{M}_{n_y,n_h}(\\mathbb{R})$\n",
    "* $b_h\\in\\mathcal{M}_{n_h,1}(\\mathbb{R})$\n",
    "* $b_y\\in\\mathcal{M}_{n_y,1}(\\mathbb{R})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eca9c7-cca2-4147-85e9-a855758a7258",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Initialize the weight matrices and bias vectors. Realize the forward pass.</span>\n",
    "\n",
    "* The weights are initialized from the standard normal distribution, dividing by 1000 to reduce the initial variance. The biases are initialized to zero. \n",
    "* For the forward pass, first initialize the hidden state $h_0$ to zero, then perform each step of the RNN.\n",
    "\n",
    "**Note:** As said, dividing by 1000 the weights reduce the initial variance. This is not the best way to initialize weights, but it's simple and works for this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04741a3f-df11-4889-b324-c25ae96bd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "class RNN:\n",
    "    # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        # Weights\n",
    "        self.Whh = rd.randn(hidden_size, hidden_size) / 1000\n",
    "        self.Wxh = rd.randn(hidden_size, input_size) / 1000\n",
    "        self.Why = rd.randn(output_size, hidden_size) / 1000\n",
    "\n",
    "        # Biases\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "        \n",
    "    # ----- #\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Perform a forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "        - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "        '''\n",
    "        h = np.zeros((self.Whh.shape[0], 1))\n",
    "        \n",
    "        # Perform each step of the RNN\n",
    "        for i, x in enumerate(inputs):\n",
    "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
    "            \n",
    "        y = self.Why @ h + self.by        \n",
    "\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73c0f0-57c8-457a-963e-f7b00f85cdbb",
   "metadata": {},
   "source": [
    "**Remark:** Before looking at the solution, you can test your $\\texttt{RNN}$ class by passing any input into the network. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b462aae-40a4-4ecd-bb96-7cac866a8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/RNN_v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134b449-9af4-4e0f-b69a-2f2109e85e63",
   "metadata": {},
   "source": [
    "The binary classification is performed using the $\\texttt{softmax}$ function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e382b7-2c91-400d-bae9-d5c4a8c5c21f",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Implement the softmax function.</span>\n",
    "\n",
    "As a reminder, for $x=(x_0,\\ldots,x_n)$ and $i_0\\in[\\![0,n]\\!]$, $~softmax(x_{i_0}) = \\frac{e^{x_{i_0}}}{\\sum_i e^{x_i}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5559d7f-1ce8-4bf6-9b9f-1fe7493cd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # Applies the Softmax function to the input array.\n",
    "    return np.exp(x) / sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "445066ad-64e0-4d8f-8c63-527eb373e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/softmax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b532e5f-8b5f-4729-ade4-fdfb935cb291",
   "metadata": {},
   "source": [
    "To ensure that we have not made an implementation error, we can pass a sentence from the training set through the network. Since the network has not yet been trained, we should find that this sentence is as likely to be positive as negative, i.e., a probability vector approximately equal to [0.5, 0.5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2596c28e-0591-480c-9560-74ef4cc1864b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49999867]\n",
      " [0.50000133]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RNN\n",
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "inputs = createInputs('i am very good')\n",
    "out, _ = rnn.forward(inputs)\n",
    "\n",
    "probs = softmax(out)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4653e2b-af3b-434b-a655-dea00d664948",
   "metadata": {},
   "source": [
    "## The Backward Phase\n",
    "\n",
    "Lets move on to training. To this end, we first need a loss function. We will use the cross-entropy loss, which is often associated with the $softmax$ function. Let $\\sigma$ denotes the $softmax$ function and $y_c$ be the _correct_ class. Then:\n",
    "\n",
    "$$ \\mathcal{L} = \\mathcal{L}(x,y;W_{xh},W_{hh},W_{hy},b_h,b_y) = -\\log(p_c) \\qquad\\text{where}\\qquad p_c = \\sigma(y_c) \\,. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d002d-6db4-4662-b12f-d7dc8cf183a6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Prove that for all $i\\in[\\![0,n_y]\\!]$, \n",
    "$\\displaystyle\\quad\\frac{\\partial\\mathcal{L}}{\\partial y_i} = \\left\\{\\begin{aligned}\n",
    "    &p_i=\\sigma(y_i) & \\text{if}\\quad i\\neq c\\\\\n",
    "    &p_c-1=\\sigma(y_c)-1 & \\text{if}\\quad i=c\n",
    "\\end{aligned}\\right\\}. $</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b733e7d-b7e9-4edd-ba36-718b24ac3c47",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d048a3-5b1a-4b87-bca1-490f2289ab49",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "**Solution**: $\\mathcal{L}(y_i)=-\\log(\\sigma(y_c))$. Hence, $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial y_i}=-\\frac1{\\sigma(y_c)}\\times\\frac{\\partial\\sigma}{\\partial y_i}$.\n",
    "* If $i\\neq c$,\n",
    "$$ \\frac{\\partial\\sigma}{\\partial y_i} = \\frac{ -e^{y_c}\\times e^{y_i} }{ \\left(\\sum_ke^{y_k}\\right)^2 }\n",
    "    = \\frac{-e^{y_c}}{\\sum_ke^{y_k}}\\times\\frac{e^{y_i}}{\\sum_ke^{y_k}} = -\\sigma(y_c)\\times\\sigma(y_i) \n",
    "    \\qquad\\text{and}\\qquad\n",
    "   \\frac{\\partial\\mathcal{L}}{\\partial y_i} = -\\frac{-\\sigma(y_c)\\times\\sigma(y_i)}{\\sigma(y_c)} = \\sigma(y_i)=p_i \\,. $$\n",
    "\n",
    "* Else,\n",
    "$$ \\frac{\\partial\\sigma}{\\partial y_c} = \\frac{ e^{y_c}\\left(\\sum_ke^{y_k}\\right)-e^{y_c}\\times e^{y_c} }{ \\left(\\sum_ke^{y_k}\\right)^2 }\n",
    "    = \\frac{e^{y_c}}{\\sum_ke^{y_k}}-\\left(\\frac{e^{y_c}}{\\sum_ke^{y_k}}\\right)^2 = \\sigma(y_c)-\\sigma(y_c)^2 \n",
    "    \\qquad\\text{and}\\qquad\n",
    "   \\frac{\\partial\\mathcal{L}}{\\partial y_c} = -\\frac{\\sigma(y_c)-\\sigma(y_c)^2}{\\sigma(y_c)} = \\sigma(y_c)-1=p_c-1 \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaaeab7-29f1-4e11-9904-b443aea5a96a",
   "metadata": {},
   "source": [
    "Let us modify the $\\texttt{forward}$ function in the $\\texttt{RNN}$ class to cache the hidden states $h$ and the inputs $x$, which we will need for computing the gradients in the back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b1fdde-aec5-45d9-a7ac-8e7c820e91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        # Weights\n",
    "        self.Whh = rd.randn(hidden_size, hidden_size) / 1000\n",
    "        self.Wxh = rd.randn(hidden_size, input_size) / 1000\n",
    "        self.Why = rd.randn(output_size, hidden_size) / 1000\n",
    "\n",
    "        # Biases\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "    \n",
    "    # ----- #\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Perform a forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "        - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "        '''\n",
    "        h = np.zeros((self.Whh.shape[0], 1))\n",
    "\n",
    "        self.inputs = inputs  ### NEW ###\n",
    "        self.hs = { 0: h }    ### NEW ###\n",
    "        \n",
    "        # Perform each step of the RNN\n",
    "        for i, x in enumerate(inputs):\n",
    "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
    "            self.hs[i+1] = h  ### NEW ###\n",
    "            \n",
    "        # Compute the output\n",
    "        y = self.Why @ h + self.by\n",
    "\n",
    "        return y, h\n",
    "    \n",
    "    # ----- #\n",
    "    \n",
    "    def backprop(self, d_y, learn_rate=2e-2):\n",
    "        '''    \n",
    "        Perform a backward pass of the RNN.    \n",
    "        - d_y (dL/dy) has shape (output_size, 1).    \n",
    "        - learn_rate is a float.    \n",
    "        '''    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc4fff-8b21-436a-88b9-ea81ab890754",
   "metadata": {},
   "source": [
    "Therefore, **given a backward pass**, we can train the RNN using the following loop on all training data. \n",
    "\n",
    "From now on, we will denote $\\frac{\\partial\\mathcal{L}}{\\partial y}$ by $\\texttt{d\\_y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a16f419-b2f2-4d6b-bb8d-cc585c2ecec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49999907]\n",
      " [0.50000093]]\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "# Loop over each training example\n",
    "for x, y in train_data.items():\n",
    "    inputs = createInputs(x)\n",
    "    target = int(y)\n",
    "\n",
    "    # Forward\n",
    "    out, _ = rnn.forward(inputs)\n",
    "    probs = softmax(out)\n",
    "\n",
    "    # Build dL/dy\n",
    "    d_y = np.copy(probs)\n",
    "    d_y[target] -= 1\n",
    "    \n",
    "    # Backward\n",
    "    rnn.backprop(d_y)\n",
    "    \n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0988a72c-7760-4efc-bfe4-844ba7253568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/trainingLoop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f23f52-7393-437a-baf6-db2878ec7564",
   "metadata": {},
   "source": [
    "### Gradient Computation\n",
    "\n",
    "It is then sufficient to backpropagate the gradient to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcff619-c716-4da1-a492-0836e2ac198c",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What are the parameters of the model to optimize?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf18f38-e142-4b00-8598-8638eec82f5a",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c2f99-ef43-4a0d-beca-ebad89fc65c3",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "**Solution**: \n",
    "* The weights matrices $W_{xh}\\in\\mathcal{M}_{n_h,n_x}(\\mathbb{R})$, $W_{hh}\\in\\mathcal{M}_{n_h,n_h}(\\mathbb{R})$ and $W_{hy}\\in\\mathcal{M}_{n_y,n_h}(\\mathbb{R})$\n",
    "* The bias vectors $b_h\\in\\mathcal{M}_{n_h,1}(\\mathbb{R})$ and $b_y\\in\\mathcal{M}_{n_y,1}(\\mathbb{R})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf612ed-db24-47dc-b9b7-971b260416c0",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Compute the gradients $\\frac{\\partial\\mathcal{L}}{\\partial W_{hy}}$ and $\\frac{\\partial\\mathcal{L}}{\\partial b_y}$.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e593d8-3894-48f9-ad8f-192d7d692ff9",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601a37f-1d4c-4a43-b3e9-84fc63a55526",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "**Solution**: Recall that $y=W_{hy}h_n+b_y$, where $h_n$ is the final hidden state. Then:\n",
    "* $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hy}} \n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y}\\times\\frac{\\partial y}{\\partial W_{hy}}\n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y} h_n^{\\top} \\,;$\n",
    "    \n",
    "* $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial b_y} \n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y}\\times\\frac{\\partial y}{\\partial b_y}\n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y} \\,.$\n",
    "    \n",
    "_Note:_ Beware of the dimensions of these objects! These are not partial derivatives in $\\mathbb{R}$..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94707e-9d88-4849-b782-d0f10f37edfd",
   "metadata": {},
   "source": [
    "Finally, we need the gradients for $W_{xh}$, $W_{hh}$, and $b_h$, which are used every step during the RNN. For example, for $W_{xh}$, we have \n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial W_{xh}} \n",
    "= \\sum_{t=0}^n \\frac{\\partial\\mathcal{L}}{\\partial h_t}\\frac{\\partial h_t}{\\partial W_{xh}} $$\n",
    "because changing $W_{xh}$ affects every $h_t$, which all affect $y$ and ultimately $\\mathcal{L}$. In order to fully calculate the gradient of $W_{xh}$, we will need to backpropagate through all time-steps, which is known as Backpropagation Through Time (BPTT).\n",
    "\n",
    "<img src=\"img/bptt.png\" width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae05a60-f044-4da2-8fa9-543b380d337c",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** At a given time step $t$, compute $\\frac{\\partial h_t}{\\partial W_{xh}}$, $\\frac{\\partial h_t}{\\partial W_{hh}}$ and $\\frac{\\partial h_t}{\\partial b_h}$.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50eb5fa-99f7-443e-bfa5-3575478d2359",
   "metadata": {},
   "source": [
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd5b9a-c5d6-425b-93f8-fe3d889f172a",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "**Solution**: Recall that $h_t=\\tanh\\left( W_{xh}x_t + W_{hh}h_{t-1} + b_h \\right)$ and that $\\tanh^\\prime(x)=1-\\tanh^2(x)$. Then:\n",
    "\n",
    "* $\\displaystyle\\frac{\\partial h_t}{\\partial W_{xh}} = (1-h_t^2)\\,x_t^{\\top} \\,;$\n",
    "    \n",
    "* $\\displaystyle\\frac{\\partial h_t}{\\partial W_{hh}} = (1-h_t^2)\\,h_{t-1}^{\\top} \\,;$\n",
    "    \n",
    "* $\\displaystyle\\frac{\\partial h_t}{\\partial b_h} = (1-h_t^2) \\,.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a41d3-a841-46a2-8d96-a3e7f2a38cc9",
   "metadata": {},
   "source": [
    "The last thing we need is $\\frac{\\partial\\mathcal{L}}{\\partial h_t}$. We can calculate it recursively:\n",
    "\n",
    "$$ \\forall t\\in[\\![0,n-1]\\!]\\,,\\quad  \\dfrac{\\partial\\mathcal{L}}{\\partial h_t} \n",
    "    = \\dfrac{\\partial\\mathcal{L}}{\\partial h_{t+1}}\\times\\dfrac{\\partial h_{t+1}}{\\partial h_t} \n",
    "    = W_{hh}^{\\top}\\, \\underbrace{\\left[(1-h_t^2)\\,\\dfrac{\\partial\\mathcal{L}}{\\partial h_{t+1}}\\right]}_{\\text{term-by-term multiplication}}\n",
    "    \\qquad\\text{and}\\qquad \n",
    "    \\dfrac{\\partial\\mathcal{L}}{\\partial h_n}=W_{hy}^{\\top}\\,\\frac{\\partial\\mathcal{L}}{\\partial y} \\;.$$\n",
    "    \n",
    "_Note:_ The recursion is _backward!_ We will implement BPTT starting from the last hidden state and working backwards, so we will already have $\\frac{\\partial\\mathcal{L}}{\\partial h_{t+1}}$ by the time we want to calculate $\\frac{\\partial\\mathcal{L}}{\\partial h_t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0611406-c339-481a-ae5b-53dbc0be775c",
   "metadata": {},
   "source": [
    "#### Back-Propagation Through Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95254000-416e-452c-a205-322c781a80eb",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Using the previous gradients computations, implement the back-propagation through time.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61da59f-3b87-4f20-a2d4-8943614283d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "class RNN:\n",
    "    # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        # Weights\n",
    "        self.Whh = rd.randn(hidden_size, hidden_size) / 1000\n",
    "        self.Wxh = rd.randn(hidden_size, input_size) / 1000\n",
    "        self.Why = rd.randn(output_size, hidden_size) / 1000\n",
    "\n",
    "        # Biases\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "    \n",
    "    # ----- #\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Perform a forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "        - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "        '''\n",
    "        h = np.zeros((self.Whh.shape[0], 1))\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.hs = { 0: h }\n",
    "        \n",
    "        # Perform each step of the RNN\n",
    "        for i, x in enumerate(inputs):\n",
    "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
    "            self.hs[i + 1] = h\n",
    "            \n",
    "        # Compute the output\n",
    "        y = self.Why @ h + self.by\n",
    "\n",
    "        return y, h\n",
    "    \n",
    "    # ----- #\n",
    "    \n",
    "    def backprop(self, d_y, learn_rate=2e-2):\n",
    "        '''    \n",
    "        Perform A backward pass of the RNN.    \n",
    "        - d_y (dL/dy) has shape (output_size, 1).    \n",
    "        - learn_rate is a float.    \n",
    "        '''    \n",
    "        n = len(self.inputs)\n",
    "\n",
    "        # Calculate dL/dWhy and dL/dby.\n",
    "        d_Why = d_y @ self.hs[n].T\n",
    "        d_by = d_y\n",
    "        \n",
    "        # Initialize dL/dWhh, dL/dWxh, and dL/dbh to zero.\n",
    "        d_Whh = np.zeros(self.Whh.shape)\n",
    "        d_Wxh = np.zeros(self.Wxh.shape)\n",
    "        d_bh = np.zeros(self.bh.shape)\n",
    "\n",
    "        # Calculate dL/dh for the last h.\n",
    "        d_h = self.Why.T @ d_y\n",
    "\n",
    "        # Backpropagate through time.\n",
    "        for t in reversed(range(n)):\n",
    "            # An intermediate value: dL/dh * (1 - h^2)\n",
    "            tmp = d_h * (1 - self.hs[t + 1] ** 2)\n",
    "\n",
    "            # dL/db = dL/dh * (1 - h^2)\n",
    "            d_bh += tmp\n",
    "            # dL/dWhh = dL/dh * (1 - h^2) * h_{t-1}\n",
    "            d_Whh += tmp @ self.hs[t].T\n",
    "            # dL/dWxh = dL/dh * (1 - h^2) * x\n",
    "            d_Wxh += tmp @ self.inputs[t].T\n",
    "            # Next dL/dh = dL/dh * (1 - h^2) * Whh\n",
    "            d_h = self.Whh.T @ tmp\n",
    "            \n",
    "        # Clip to prevent exploding gradients.\n",
    "        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n",
    "            np.clip(d, -1, 1, out=d)\n",
    "            \n",
    "        # Update weights and biases using gradient descent.\n",
    "        self.Whh -= learn_rate * d_Whh\n",
    "        self.Wxh -= learn_rate * d_Wxh\n",
    "        self.Why -= learn_rate * d_Why\n",
    "        self.bh -= learn_rate * d_bh\n",
    "        self.by -= learn_rate * d_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e8da0ca-8352-4e1e-8ec2-9913816a59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/RNN_v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedbd00-7275-4403-990f-6fa1a2a55149",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edd547-6da6-4f91-a222-f889a1140af2",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Write a helper function to process data with the RNN.</span>\n",
    "\n",
    "To do this, you can refer to the various tests we have carried out previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d7b2ed5-59a0-482d-ad7f-a3636c63721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data, backprop=True):\n",
    "    '''\n",
    "    Returns the RNN's loss and accuracy for the given data.\n",
    "    - data is a dictionary mapping text to True or False.\n",
    "    - backprop determines if the backward phase should be run.\n",
    "    '''\n",
    "    items = list(data.items())\n",
    "    random.shuffle(items)\n",
    "\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for x, y in items:\n",
    "        inputs = createInputs(x)\n",
    "        target = int(y)\n",
    "\n",
    "        # Forward\n",
    "        out, _ = rnn.forward(inputs)\n",
    "        probs = softmax(out)\n",
    "\n",
    "        # Calculate loss / accuracy\n",
    "        loss -= np.log(probs[target])\n",
    "        num_correct += int(np.argmax(probs) == target)\n",
    "\n",
    "        if backprop:\n",
    "            # Build dL/dy\n",
    "            d_y = np.copy(probs)\n",
    "            d_y[target] -= 1\n",
    "\n",
    "            # Backward\n",
    "            rnn.backprop(d_y)\n",
    "\n",
    "    return loss/len(data), num_correct/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33acc766-bb03-4d82-8d32-037621d9de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/processData.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ce1e1-ea95-4543-84f1-17b798e5cc4b",
   "metadata": {},
   "source": [
    "Last, we can write the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "780f3764-56bc-4005-9772-34f25e1ddace",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 100\n",
      "Train:\tLoss 0.688 | Accuracy: 0.552\n",
      "Test:\tLoss 0.695 | Accuracy: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89133/985038822.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Train:\\tLoss %.3f | Accuracy: %.3f' % (train_loss, train_acc))\n",
      "/tmp/ipykernel_89133/985038822.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Test:\\tLoss %.3f | Accuracy: %.3f' % (test_loss, test_acc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 200\n",
      "Train:\tLoss 0.662 | Accuracy: 0.672\n",
      "Test:\tLoss 0.713 | Accuracy: 0.450\n",
      "--- Epoch 300\n",
      "Train:\tLoss 0.142 | Accuracy: 0.983\n",
      "Test:\tLoss 0.170 | Accuracy: 1.000\n",
      "--- Epoch 400\n",
      "Train:\tLoss 0.010 | Accuracy: 1.000\n",
      "Test:\tLoss 0.012 | Accuracy: 1.000\n",
      "--- Epoch 500\n",
      "Train:\tLoss 0.005 | Accuracy: 1.000\n",
      "Test:\tLoss 0.006 | Accuracy: 1.000\n",
      "--- Epoch 600\n",
      "Train:\tLoss 0.003 | Accuracy: 1.000\n",
      "Test:\tLoss 0.004 | Accuracy: 1.000\n",
      "--- Epoch 700\n",
      "Train:\tLoss 0.002 | Accuracy: 1.000\n",
      "Test:\tLoss 0.003 | Accuracy: 1.000\n",
      "--- Epoch 800\n",
      "Train:\tLoss 0.002 | Accuracy: 1.000\n",
      "Test:\tLoss 0.002 | Accuracy: 1.000\n",
      "--- Epoch 900\n",
      "Train:\tLoss 0.001 | Accuracy: 1.000\n",
      "Test:\tLoss 0.002 | Accuracy: 1.000\n",
      "--- Epoch 1000\n",
      "Train:\tLoss 0.001 | Accuracy: 1.000\n",
      "Test:\tLoss 0.001 | Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    train_loss, train_acc = processData(train_data)\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print('--- Epoch %d' % (epoch + 1))\n",
    "        print('Train:\\tLoss %.3f | Accuracy: %.3f' % (train_loss, train_acc))\n",
    "\n",
    "        test_loss, test_acc = processData(test_data, backprop=False)\n",
    "        print('Test:\\tLoss %.3f | Accuracy: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5a81b-ad5d-492c-85eb-019037c79179",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Visualize the results of the training on the test data.</span>\n",
    "\n",
    "You will use the same color code as for the visualization of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c186ecee-9f92-4604-afc6-e558175c55e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mthis is happy\n",
      "\u001b[32mi am good\n",
      "\u001b[31mthis is not happy\n",
      "\u001b[31mi am not good\n",
      "\u001b[32mthis is not bad\n",
      "\u001b[32mi am not sad\n",
      "\u001b[32mi am very good\n",
      "\u001b[31mthis is very bad\n",
      "\u001b[31mi am very sad\n",
      "\u001b[31mthis is bad not good\n",
      "\u001b[32mthis is good and happy\n",
      "\u001b[31mi am not good and not happy\n",
      "\u001b[32mi am not at all sad\n",
      "\u001b[31mthis is not at all good\n",
      "\u001b[32mthis is not at all bad\n",
      "\u001b[32mthis is good right now\n",
      "\u001b[31mthis is sad right now\n",
      "\u001b[31mthis is very bad right now\n",
      "\u001b[32mthis was good earlier\n",
      "\u001b[31mi was not happy and not good earlier\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Visualize the results\n",
    "test_res = test_data\n",
    "\n",
    "for _, w in enumerate(test_res):\n",
    "    inputs = createInputs(w)\n",
    "    out, _ = rnn.forward(inputs)\n",
    "    res = softmax(out)<.5\n",
    "    res = bool(res[0])\n",
    "    test_res[w] = res\n",
    "    \n",
    "    if res:\n",
    "        print(Fore.GREEN + w)\n",
    "    else:\n",
    "        print(Fore.RED + w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "861f04e8-5a21-4d64-b3d6-f0beaffab2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/coloredResults.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73994082-8f7d-4670-8228-81c138987c3f",
   "metadata": {},
   "source": [
    "# **Part II**: Study of the [IMDB](http://ai.stanford.edu/~amaas/data/sentiment/) Dataset\n",
    "\n",
    "<img src=\"img/imdb.png\" width=500>\n",
    "\n",
    "In this second part, we will train a classifier movie reviews in IMDB data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a5d5a77-5e48-411a-900d-02a3a099f29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 17:08:52.625430: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-18 17:08:52.668553: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-18 17:08:52.880488: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 17:08:52.880595: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 17:08:52.881568: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 17:08:52.977888: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-18 17:08:52.979786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 17:08:54.811992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1241d4-2b21-4681-8961-fe79735df19e",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d50de66b-11bb-489a-aaba-0199b2f8da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n",
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(start_char=1, oov_char=2, index_from=3)\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e757e60-06ff-4bd9-926a-762ec0cf6cbd",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "The commands below allow displaying a sample review and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "697f2089-488b-4ec7-9727-b1643a7887aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review number---\n",
      "20307\n",
      "\n",
      "---review---\n",
      "[1, 1025, 85, 19080, 37, 28, 4293, 23, 14, 1327, 1256, 8, 12071, 1522, 53114, 13, 104, 15, 14, 976, 22, 1568, 6, 1315, 5, 933, 65, 15, 10077, 39825, 3089, 5, 4, 302, 8481, 2079, 4189, 17999, 65, 19, 6, 4690, 508, 5, 2778, 744, 41175, 14, 1360, 10669, 1082, 8, 17647, 7, 5119, 2350, 25695, 35946, 2118, 885, 2349, 4, 6615, 7, 4, 428, 10801, 13, 104, 14, 22, 238, 30, 6, 227, 99, 654, 11, 4, 130, 190, 12, 9, 1685, 20947, 11, 11505, 298, 1181, 5, 15092, 8, 4, 213, 15, 49, 428, 13488, 203, 79, 4, 547, 7, 267, 83, 4, 113, 7, 14, 11505, 298, 5200, 3873, 13, 28, 712, 19, 4, 9209, 1251, 7, 4, 22, 21, 54, 75, 168, 33, 938, 50, 26, 24, 111, 2837, 42, 4941, 18, 328, 349, 37, 26, 71, 11, 17999, 904, 42, 729, 1186, 797, 203, 140, 8, 14, 20, 1017, 6, 328, 20, 51, 9, 6, 328, 20, 10, 10, 81, 2118, 7, 27044, 15546, 1392, 8452, 686, 4069, 6153, 5, 38, 2589, 17685, 6, 328, 20, 13, 104, 2079, 17, 167, 3892, 15, 11505, 1531, 5, 85, 84, 7, 1399, 855, 19, 406, 712, 40, 2569, 5, 18111, 10369, 8, 403, 6, 171, 134, 712, 28, 4822, 5, 18586, 64, 77, 348, 641, 5, 15120, 2864, 52, 80, 3266, 5, 85, 428, 102, 45, 312, 58, 36, 71, 348, 4, 172, 4637, 5, 15120, 17, 68, 428, 8237, 11, 5, 46, 7, 4, 1776, 10, 10, 619, 8, 135, 151, 11, 14, 2758, 704, 3387, 2079, 5, 3544, 2175, 80, 242, 28, 8, 858, 160, 747, 153, 159, 36, 3911, 35, 735, 42, 233, 334, 36, 199, 80, 28, 8, 858, 366, 36, 1504, 42, 323, 11, 6, 20, 15, 18970, 4, 644, 2758, 5, 7901, 2118, 8, 79, 35, 735, 15, 9, 8, 135, 3387, 1816, 2128, 18, 9859, 1745, 12648, 5, 409, 159, 15, 23751, 2333, 251, 735, 15, 9, 24, 8, 33628, 42, 3655, 1212, 85, 87, 1507, 5, 156, 7, 1399, 37, 26, 9404, 68, 688, 2822, 18, 5792, 157, 246, 363, 62, 247, 2222, 4, 749, 15, 3089, 5, 13207, 5, 65382, 26, 3472, 34, 25695, 5, 60, 6586, 148, 2118, 17, 36, 977, 11, 3356, 108, 141, 17, 298, 936, 2927, 11, 4, 4056, 7, 52, 5, 445, 298, 3274, 5, 60, 825, 19, 4, 1933, 10, 10, 3544, 2175, 9, 6, 19913, 284, 5, 13, 657, 90, 118, 32, 7, 4, 85, 1507, 5, 156, 520, 897, 354, 957, 180, 261, 13, 81, 193, 1834, 19, 24294, 5560, 7, 246, 160, 730, 5376, 641, 9700, 74506, 15, 301, 316, 144, 106, 14, 22, 190, 12, 203, 24, 30, 18, 316, 76, 33338, 158, 158]\n",
      "\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "idx = rd.randint(len(X_train))\n",
    "\n",
    "print('---review number---')\n",
    "print(idx)\n",
    "\n",
    "print('\\n---review---')\n",
    "print(X_train[idx])\n",
    "\n",
    "print('\\n---label---')\n",
    "print(y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324158e-1507-4166-92ef-17f9754f5861",
   "metadata": {},
   "source": [
    "The review is stored as a sequence of integers. These are word IDs that have been pre-assigned to individual words, based on their frequencies: the more frequent a word, the lower the integer. The label is an integer (0 for negative, 1 for positive).\n",
    "\n",
    "To decode the review, we need to use the vocabulary, _i.e._, the dictionary that associates each word with its unique integer ID, which is available via the `get_word_index()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7ae1a01-aafe-424f-a258-cf317a3f2099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pad_char = 0\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "\n",
    "word_to_idx = imdb.get_word_index()\n",
    "idx_to_word = {i+index_from: w for (w, i) in word_to_idx.items()}\n",
    "idx_to_word[pad_char] = \"[PAD]\"\n",
    "idx_to_word[start_char] = \"[START]\"\n",
    "idx_to_word[oov_char] = \"[OOV]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c5f154-6256-4112-8462-d80be4a535cb",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Write a function that displays a review in a readable form along with its label.</span>\n",
    "\n",
    "Keep a similar display to the one suggested above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78d2d771-5e3a-474e-a71c-d44c94080845",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def decodeReview(idx):\n",
    "    '''\n",
    "    Converts the encoded idx-th review to human readable form.\n",
    "    Displays the review number, the review in words and the label\n",
    "    '''\n",
    "    print('---review number---')\n",
    "    print(idx)\n",
    "\n",
    "    print('\\n---review in words---')\n",
    "    print(\" \".join(idx_to_word[i] for i in X_train[idx]))\n",
    "\n",
    "    print('\\n---label---')\n",
    "    print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea724d3a-805c-4106-bce7-173f6470539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/decodeReview.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41dd2b39-656e-4a68-9886-d013c25f0d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review number---\n",
      "20307\n",
      "\n",
      "---review in words---\n",
      "[START] unlike other commenters who have commented on this movie's ability to transcend race contrarily i think that this powerful film provides a complex and deep story that addresses institutional racism and the effects thereof washington directs fisher's story with a careful hand and critical eye relinquishing this cinematic endeavor neither to dismemberment of women's bodies perpetuating unthoughtful stereotypes nor satisfying the expectation of the white gaze i think this film might be a bit too happy in the end however it is deeply entrenched in afro american culture and discourse to the point that some white spectators may get the feeling of looking into the life of this afro american antwone fisher i have problems with the naval aspect of the film but when we look at america there are not many choices or opportunities for black men who are were in fisher's situation or similar situations viewers may go to this movie expecting a black movie what is a black movie br br do stereotypes of pimps whores drug dealers single parent homes and so forth constitute a black movie i think washington as director recognized that afro americans and other people of color deal with human problems like abuse and displaced aggression to name a few these problems have historically and presently only been given light and validity via good will hunting and other white movies it's high time they were given the same recognition and validity as their white counterparts in and out of the media br br sad to say though in this racist country denzel washington and derek luke will probably have to wait another ten years before they receive an oscar or anything else they both will have to wait until they direct or star in a movie that perpetuates the usual racist and sexist stereotypes to get an oscar that is to say denzel deserved awards for malcolm x hurricane and others before that jive training day oscar that is not to negate or push aside other great actresses and actors of color who are denied their due praise for ingenious work yet hollywood would rather send the message that racism and sexism and heterosexism are acceptable by perpetuating and even rewarding those stereotypes as they appear in countless films such as american beauty midnight in the garden of good and evil american pie and even gone with the wind br br derek luke is a helluva actor and i wish him best all of the other actresses and actors gave superb performances hands down although i do take issue with denzel's selection of yet another straight haired light skinned sistuh that said everyone should watch this film however it may not be for everyone much luv 10 10\n",
      "\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "decodeReview(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bb9e8-3dee-44fe-92a8-bc550315fc50",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What is the proportion of positive reviews in the training dataset? And in the test dataset?</span>\n",
    "\n",
    "This question can be answered using a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "836342a5-87df-4ec8-986f-563a81a2eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train distribution:  {0: 12500, 1: 12500}\n",
      "y_test distribution:  {0: 12500, 1: 12500}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Proportion of positive reviews\n",
    "plt.figure(figsize = (8,3))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.countplot(x=y_train)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"y_train\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.countplot(x=y_test)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"y_test\")\n",
    "\n",
    "\n",
    "unique,  counts = np.unique(y_train, return_counts = True)\n",
    "print(\"y_train distribution: \", dict(zip(unique,counts)))\n",
    "\n",
    "unique,  counts = np.unique(y_test, return_counts = True)\n",
    "print(\"y_test distribution: \", dict(zip(unique,counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cb933fe-182e-472c-8450-2d70828b0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/positiveProportion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3466221-afef-4569-b938-3a5ae2fc9f55",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** How many different words does this database contain?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4d2e24c-bddd-41f6-85cc-a3938afab55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584 unique words found\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "vocab_size = len(imdb.get_word_index())\n",
    "print('%d unique words found' % vocab_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4bf6811-438e-4642-9b31-6e49536b97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/vocab_size.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0cef1b-cdcf-45b0-86b8-210525b53f65",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** Are all reviews the same length? If not, what is their maximum length?</span>\n",
    "\n",
    "This question can be answered using an histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccf5ccf3-b7aa-4b0a-8aa9-cd80eb2265fa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2494\n",
      "Minimum review length: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Lengths of the reviews\n",
    "train_lengths = []\n",
    "for x in X_train:\n",
    "    train_lengths.append(len(x))\n",
    "    \n",
    "test_lengths = []\n",
    "for x in X_test:\n",
    "    test_lengths.append(len(x))\n",
    "    \n",
    "    \n",
    "plt.figure(figsize = (10,6))\n",
    "sns.histplot(x=train_lengths, color='orange', alpha=.8)\n",
    "sns.histplot(x=test_lengths, alpha=.5)\n",
    "plt.legend(['train lengths', 'test lengths'])    \n",
    "\n",
    "\n",
    "print('Maximum review length: {}'.format(max(train_lengths+test_lengths)))\n",
    "print('Minimum review length: {}'.format(min(train_lengths+test_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84721a47-77f6-472f-984a-f6e489c937f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/reviewsLengths.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5573faf-8645-44c4-bfb0-48f4b949bbcf",
   "metadata": {},
   "source": [
    "### Sequences Padding\n",
    "\n",
    "The reviews have a variable number of words, while the network has a fixed number of neurons. To get a fixed length input, we can simply truncate the reviews to a fixed number of words, say $\\texttt{max\\_words=200}$. To facilitate learning, we will also limit ourselves to the $\\texttt{vocab\\_size=10000}$ most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604b375-3eb0-4785-a96a-076088893e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1f3ad-6907-4a6b-9fb8-c64828665dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "vocab_size = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(start_char=1, oov_char=2, index_from=3, num_words = vocab_size)\n",
    "\n",
    "X_train_pad = sequence.pad_sequences(X_train, value=0, padding='post', maxlen=max_words)\n",
    "X_test_pad = sequence.pad_sequences(X_test, value=0, padding='post', maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e95cf-98a2-439b-bd18-1c6ffe9bd09b",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Check that the size of the reviews is now equal to $\\texttt{max\\_words}$ for each of them.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173e230-e8aa-488c-99cd-05b6cec5c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Lengths of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d19b7-f34d-40ec-9193-509423364404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/paddingLengths.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d855fcf-62ed-4ee9-8920-acadd29156b4",
   "metadata": {},
   "source": [
    "Let us see the effect of padding and truncation at the most frequent words on the previously displayed idx-th review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d2e49-d0d9-4e71-806c-d17872c48c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodeReview(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6fdc4-fee5-4070-80c8-0fe5b8e07399",
   "metadata": {},
   "source": [
    "## RNN for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecbc185-fa3c-48fd-b2d8-d9fdda80177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, SimpleRNN, LSTM, Dense, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6200be4-1088-4b0b-b37b-e512ef8ea133",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Design a RNN model for sentiment analysis.</span>\n",
    "\n",
    "The first layer must be an [`Embedding`](https://keras.io/api/layers/core_layers/embedding/) layer. To prevent gradient vanishing, choose a suitable recurrent network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9040f769-e436-46a9-8251-6ad95a8f5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "embedding_size = 32\n",
    "\n",
    "rnn = Sequential(name=\"RNN\")\n",
    "rnn.add(Embedding(vocab_size, embedding_size))  #, input_length=max_words\n",
    "[...]\n",
    "\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503022c-2e7a-4df3-80eb-7ed88a7f67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/rnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790cd29-8efe-4323-8d8e-636b552825de",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Performing the learning.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0d5e2-9a27-4726-bd1d-454f225cdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train[batch_size:]\n",
    "\n",
    "\n",
    "rnn.compile(loss=..., \n",
    "             optimizer=..., \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_rnn = rnn.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99f0b1-e4bd-4ed7-acbf-6f3fec9be06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/rnnTraining.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a15083-b62d-4f38-b9f0-d20d61eab224",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Visualize the learning process.</span>\n",
    "\n",
    "Write a function that allows to represent on two different figures the accuracy on one hand, and the loss on the other hand, each for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e2881-62e5-45f4-89b7-b37903fa9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def plotTraining(history):\n",
    "    [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c3829-0d53-4e1c-bc06-3308c4d4a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/plotTraining.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d4c15-7cbe-4c9c-882c-f343c8215dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTraining(history_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237b8c5-61bf-48bc-9ee5-7da2c5fb0ed1",
   "metadata": {},
   "source": [
    "## Bidirectional RNN\n",
    "\n",
    "As defined, this network introduces a causal structure into the data. Also, for text processing, we often prefer a bidirectional network. To do this, we can use the [`Bidirectional`](https://keras.io/api/layers/recurrent_layers/bidirectional/) command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee2e3c-588b-45f4-abff-f59217850130",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "bi_rnn = Sequential(name=\"Bidirectional_RNN\")\n",
    "bi_rnn.add(Embedding(vocab_size, embedding_size))\n",
    "bi_rnn.add(Bidirectional(LSTM(int(.5*embedding_size))))  ### NEW ###\n",
    "bi_rnn.add(Dropout(0.1))\n",
    "bi_rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(bi_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a81c21-bed6-4f9d-b8e8-c2f1cb251a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train[batch_size:]\n",
    "\n",
    "\n",
    "bi_rnn.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_bi_rnn = bi_rnn.fit(X_train_rnn, \n",
    "                    y_train_rnn, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "plotTraining(history_bi_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023b1b0-0e6d-4d76-bf53-1abb53b34dad",
   "metadata": {},
   "source": [
    "Thanks to the $\\texttt{return\\_sequences}$ option, we can easily stack several RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b9883-309f-40b8-99c5-b1706115dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "bi2_rnn = Sequential(name=\"Double_Bidirectional_RNN\")\n",
    "bi2_rnn.add(Embedding(vocab_size, embedding_size))\n",
    "bi2_rnn.add(Bidirectional(LSTM(int(.5*embedding_size), return_sequences = True)))\n",
    "bi2_rnn.add(Bidirectional(LSTM(int(.5*embedding_size), return_sequences = False)))\n",
    "bi2_rnn.add(Dropout(0.1))\n",
    "bi2_rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(bi2_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7ef75-0bcf-4cce-b16f-962448b79d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train[batch_size:]\n",
    "\n",
    "\n",
    "bi2_rnn.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_bi2_rnn = bi2_rnn.fit(X_train_rnn, \n",
    "                    y_train_rnn, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "plotTraining(history_bi2_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1239e-fc01-4e3e-80f4-b90cf13449b6",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ffb9e-f111-421b-b807-2d9e7108662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d910c-b6f3-4190-bf04-64b7cd2bfdd0",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Compare the confusion matrices for the three models proposed above.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9feee-09c1-4900-96a0-4af1f97d8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Compare the confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60fa15-4e03-4779-939d-21543df46dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/confusion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d183f7d-c21b-4417-ab91-102b43e604bd",
   "metadata": {},
   "source": [
    "## MLP for Sentiment Analysis\n",
    "\n",
    "Just to be sure of the usefulness of a recurrent network, we decide to test a \"simple\" perceptron on the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c556d-97ab-4d2d-8471-4feb3a050909",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Compare the above results with those of an MLP. Conclude.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38429f1f-d6d2-4111-8a23-4dc706e9c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Comparison with a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7eb79-76ae-4a5a-89fe-39197ef46b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2b16d-f333-49f6-b0b7-7daef40cba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2541478-c6fa-4d0b-bbfb-3ddc821ca33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
